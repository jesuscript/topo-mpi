"""
Example of a LISSOM-based position, orientation, direction, speed,
ocular dominance, disparity, spatial frequency, and color preference
map.

Orientation, direction, ocular dominance, disparity, spatial frequency
and color dimensions can be turned on and off.  All maps have position
information, and speed is always present when direction is included.

Here are examples of the commands that you could use to get the specified combinations of maps:

  OR:               ./topographica -c "dims=['or']"                     examples/lissom.ty
  OR/DR:            ./topographica -c "dims=['or','dr']"                examples/lissom.ty
  OR/OD:            ./topographica -c "dims=['or','od']"                examples/lissom.ty
  OR/RG:            ./topographica -c "dims=['or','rg']"                examples/lissom.ty
  OR/OD/DR:         ./topographica -c "dims=['or','od','dr']"           examples/lissom.ty
  OR/OD/DR/DY:      ./topographica -c "dims=['or','od','dr','dy']"      examples/lissom.ty
  OR/OD/DR/DY/SF:   ./topographica -c "dims=['or','od','dr','dy','sf']" examples/lissom.ty
  OR/OD/DR/DY/RG:   ./topographica -c "dims=['or','od','dr','dy','rg']" examples/lissom.ty
  OR/OD/DR/DY/CR:   ./topographica -c "dims=['or','od','dr','dy','cr']" examples/lissom.ty
  OR/OD/DR/DY/CR/SF:./topographica -c "dims=['or','od','dr','dy','cr','sf']" examples/lissom.ty

OR/OD/DR/DY is the default.

You can also select different training datasets:
 Gaussians:      ./topographica -c "dataset='Gaussian'" examples/lissom.ty
 Natural images: ./topographica -c "dataset='Nature'"   examples/lissom.ty  
 Color images:   ./topographica -c "dataset='FoliageB'" examples/lissom.ty  
Gaussian is the default.

These simulations are intended to be close (but approximate) matches
to the various map simulations in chapter 5 of Miikkulainen, Bednar,
Choe, and Sirosh (2005), Computational Maps in the Visual Cortex,
Springer.  Specifically:

    dataset='Gaussian', dims=['or']:           CVMC Figure 5.9
    dataset='Nature',   dims=['or']:           CVMC Figure 5.13 Nature
    dataset='Gaussian', dims=['od','dr']:      CVMC Figure 5.23
    dataset='Gaussian', dims=['or','od']:      CVMC Figure 5.27
    dataset='Gaussian', dims=['or','od','dr']: CVMC Figure 5.29
    dataset='Nature',   dims=['or','od','dr']: CVMC Figure 5.31

Known differences include:

 - The default_density is smaller for practicality (142 in the book).
 - The matching is not yet perfect at different densities
 - The lateral inhibitory radius is up to 0.5 matrix units greater
   than in the book, because Topographica enforces good
   circular-shaped CF outlines.
 - Input patterns are evaluated on the entire retina, instead of only up
   to bounds_multiplier=2.5 times the gaussian sigma in the book
 - Initial weight patterns are not smoothed around the edges, unlike
   smooth_circular_outlines=True and smooth_circular_radius_trim=-0.25
   used in the book
 - Initial weight patterns are all random within a gaussian envelope
   rather than random afferent and Gaussian sigma preset_sigma_exc=11.076
   preset_sigma_inh=71.76 lateral weights used in the book.
 - Inhibitory weight pruning is disabled (not pruning all weights below
   1e-5 as in the book)

There may be other small differences, as this file has not yet been
compared exhaustively to the original simulations.

Furthermore, some combinations of dimensions can approximately replicate 
various map simulations in:

 - Tikesh Ramtohul. A self-organizing model of disparity maps in the
   primary visual cortex. Master's thesis, The University of
   Edinburgh, Scotland, UK, 2006.
 - James A. Bednar, Judah B. De Paula, and Risto Miikkulainen.
   Self-organization of color opponent receptive fields and laterally
   connected orientation maps. Neurocomputing, 65-66:69-76, 2005.
 - Judah Ben De Paula. Modeling the Self-Organization of Color
   Selectivity in the Visual Cortex.  PhD thesis, Department of
   Computer Sciences, The University of Texas at Austin, Austin, TX,
   2007.
 - Christopher M. Palmer and James A. Bednar. Topographic and laminar
   organization of spatial frequency and orientation in a
   developmental model of V1 using natural images. In Society for
   Neuroscience Abstracts, Society for Neuroscience, www.sfn.org,
   2007. Program No. 395.13.

Specifically:
    dataset='Gaussian',    dims=['or','dy']:           ramtohul:msc06
    dataset='FoliageA',    dims=['or','rg']:           jbednar:neurocomputing05
    dataset='FoliageB',    dims=['or','cr']:           depaula:phd07
    dataset='Nature',      dims=['or','sf']:           palmer:sfn07

$Id: lissom.ty 9653 2008-12-04 14:32:50Z jbednar $
"""
__version__='$Revision: 8706 $'


from math import pi, sqrt
import numpy
import copy

from colorsys import hsv_to_rgb

from topo import learningfn,numbergen,transferfn,pattern,projection,responsefn,sheet 

import topo.learningfn.optimized
import topo.learningfn.projfn 
import topo.transferfn.optimized 
import topo.pattern.random
import topo.pattern.image
import topo.responsefn.optimized 
import topo.sheet.lissom
import topo.sheet.optimized


### Specify weight initialization, response function, and learning function
projection.CFProjection.cf_shape=pattern.Disk(smoothing=0.0)
projection.CFProjection.weights_generator=pattern.Constant()
projection.CFProjection.response_fn=responsefn.optimized.CFPRF_DotProduct_opt()
projection.CFProjection.learning_fn=learningfn.optimized.CFPLF_Hebbian_opt()
projection.CFProjection.weights_output_fn=transferfn.optimized.CFPOF_DivisiveNormalizeL1_opt()
projection.SharedWeightCFProjection.response_fn=responsefn.optimized.CFPRF_DotProduct_opt()

### Default for tutorial
pattern.Line.scale=0.9
pattern.Gaussian.size=0.08333
pattern.Gaussian.aspect_ratio=4.0

numpy.random.seed((500,500))


### Set up parameters for specified type of simulation

# Defaults:                         # parameters for:
center_polarities=['On','Off']      # oo
rg_cone_types=['']                  # rg
cone_types=['']                     # rg,cr
opponent_types=['']                 # rg
basic_opponent_types=['']           # rg 
eyes=['']                           # od,dy
lags=['']                           # dr
num_lags=0                                                      #dr
speed=0.0                           # dr
disparity_bound = 0.0               # dy
position_bound = 0.75               # dy
sf_channels = 1                     # sf
sf_spacing = 2.0                    # sf
v1aff_radius=0.27083                # sf
lgnaff_radius=0.375                 # sf

dims=locals().get('dims',['or','od','dr','dy'])

# Convenient shortcut:
if dims=='All': dims=['or','od','dr','dy','cr','sf']

topo.sim.name = "lissom_oo_" + '_'.join(dims)
if 'od' in dims or 'dy' in dims:
    eyes=['Left','Right']
    
if 'dr' in dims: 
    lags=['0','1','2','3']
    num_lags=len(lags)
    speed=2.0 # Useful speeds range from 0.0 - 3.0.

if 'dy' in dims: 
    max_disparity = locals().get('max_disparity',4.0)
    disparity_bound = max_disparity*0.041665/2.0
    if max_disparity > 0.0: position_bound = 0.70833

if 'rg' in dims:
    rg_cone_types=['Red','Green']
    cone_types=['Red','Green']
    opponent_types=['Red-Green ','Green-Red ','Luminosity ']    
    basic_opponent_types=['Red-Green ','Green-Red ']  

if 'cr' in dims:
    rg_cone_types=['Red','Green']
    cone_types=['Red','Green','Blue']
    opponent_types=['Red-Green ','Green-Red ','Blue-RedGreen ','Luminosity ']
    basic_opponent_types=['Red-Green ','Green-Red '] 
    dims.append('rg')

if 'sf' in dims:
    sf_channels=2 # Useful values are 2,3,4.

# Should rewrite the code below in terms of these lists for
# consistency and to allow arbitrary lists of sizes.
sf_channel_nums=range(1,sf_channels+1)
sf_relative_sizes=[sf_spacing**(channel-1) for channel in sf_channel_nums]


### Input patterns and LGN sheets
num_inputs=1
dataset=locals().get('dataset',"Gaussian")

# CB: not sure this is the clearest way to do it...
# (also need to rename 'colormap').
natural_image_sets = ['Nature','FoliageA','FoliageB']
# Could we avoid some of the various ifs in this file by using
# dictionaries?
# I haven't yet used this file enough to know what's best...
    
if dataset=="Gaussian":
    input_type=pattern.Gaussian
    ids=1.0
elif dataset in natural_image_sets:
    input_type=pattern.image.FileImage
    ids=4.0
        
default_retina_density=locals().get('default_retina_density',48.0 \
                                    if dataset in natural_image_sets or 'dy' in dims else 24.0)

# helper fns for synthesizing a specified hue
def h_to_r(h): return hsv_to_rgb(h,1.0,1.0)[0]
def h_to_g(h): return hsv_to_rgb(h,1.0,1.0)[1]
def h_to_b(h): return hsv_to_rgb(h,1.0,1.0)[2]

for e in eyes:
    for cone in cone_types:

        if dataset=="Gaussian":
            r=0 if 'rg' not in dims else numbergen.UnaryOperator(
                numbergen.UniformRandom(lbound=0,ubound=1,seed=78),h_to_r)
            g=0 if 'rg' not in dims else numbergen.UnaryOperator(
                numbergen.UniformRandom(lbound=0,ubound=1,seed=78),h_to_g)
            b=0 if 'cr' not in dims else numbergen.UnaryOperator(
                numbergen.UniformRandom(lbound=0,ubound=1,seed=78),h_to_b)

            inputs=[input_type(
                x=numbergen.UniformRandom(lbound=-position_bound,ubound=position_bound,seed=12+i) + \
                  numbergen.UniformRandom(lbound=-disparity_bound,ubound=disparity_bound,seed=150+i)*(-1)**(e=='Left'),
                y=numbergen.UniformRandom(lbound=-0.75,ubound=0.75,seed=34+i),
                orientation=0 if 'dr' in dims else numbergen.UniformRandom(lbound=-pi,ubound=pi,seed=56+i),                                             ###
                size=0.088388*(3**('or' not in dims)) * \
                  numbergen.UniformRandom(lbound=1,ubound=sf_spacing**(sf_channels-1),
                                          seed=23+i)**('sf' in dims), 
                aspect_ratio=4.66667 if 'or' in dims else 1.0,
                scale=2.0-2*(r*(cone=='Red')+g*(cone=='Green')+b*(cone=='Blue')) - \
                  numbergen.UniformRandom(lbound=0,ubound=2,seed=78+i)*('rg' not in dims) \
                  if e=='Right' and 'od' in dims else \
                  2*(r*(cone=='Red')+g*(cone=='Green')+b*(cone=='Blue')) + \
                  numbergen.UniformRandom(lbound=0,ubound=2,seed=78+i)*('rg' not in dims),
                bounds=sheet.BoundingBox(radius=0.8))
            for i in xrange(num_inputs)]
            input_composite=pattern.SeparatedComposite(min_separation=2.2*v1aff_radius,generators=inputs)

        elif dataset in natural_image_sets:
            scalingfactor=[1.4*0.9,1.4,1.4*0.97] if 'cr' in dims else [1.0,1.0,1.0]
            if dataset=="FoliageA":
                image_filenames=["images/mcgill/foliage_a/%02d_%d.png"%(i,cone_types.index(cone))
                                 for i in xrange(5)]
            elif dataset=="FoliageB":
                image_filenames=["images/mcgill/foliage_b/%02d_%d.png"%(i,cone_types.index(cone))
                                 for i in xrange(1,26)]
            elif dataset=="Nature":
                image_filenames=["images/shouval/combined%02d.png"%(i+1) for i in xrange(25)]

            inputs=[input_type(
                filename=f, size=10.0, cache_image=False,
                x=numbergen.UniformRandom(lbound=-0.75,ubound=0.75,seed=12) + \
                numbergen.UniformRandom(lbound=-disparity_bound,ubound=disparity_bound,
                                        seed=150)*(-1)**(e=='Left'),
                y=numbergen.UniformRandom(lbound=-0.75,ubound=0.75,seed=34),
                orientation=0 if dr in dims else numbergen.UniformRandom(lbound=-pi,ubound=pi,seed=56),
                scale=2.0-numbergen.UniformRandom(lbound=0,ubound=2,seed=78)*scalingfactor[cone_types.index(cone)] \
                if e=='Right' and 'od' in dims else \
                numbergen.UniformRandom(lbound=0,ubound=2,seed=78)*scalingfactor[cone_types.index(cone)])
            for f in image_filenames]
            input_composite=pattern.Selector(generators=inputs)

        else:
            raise ValueError("Unknown dataset '%s'"%dataset)

        input_period=num_lags
        if 'dr' in dims:
            input_moved=pattern.Translator(
                            x=numbergen.UniformRandom(lbound=-0.75,ubound=0.75,seed=12),
                            y=numbergen.UniformRandom(lbound=-0.75,ubound=0.75,seed=34),
                            direction=numbergen.UniformRandom(lbound=-pi,ubound=pi,seed=99),
                            generator=pattern.Gaussian(size=0.088388, aspect_ratio=4.66667, scale=1.0,
                               bounds=sheet.BoundingBox(radius=0.8)),
                            reset_period=input_period,
                                speed=0.04)     
        else: input_moved=input_composite

        topo.sim[e+cone+'Retina']=sheet.GeneratorSheet(
            nominal_density=default_retina_density,
            input_generator=input_moved,
            period=1.0, phase=0.05,
            nominal_bounds=sheet.BoundingBox(radius=0.5+v1aff_radius*sf_spacing**(sf_channels-1) + \
                                             lgnaff_radius*sf_spacing**(sf_channels-1)))
    for l in center_polarities:
        for opponent in opponent_types:
            topo.sim[e+opponent+'LGN'+l]=sheet.CFSheet(
                nominal_density=locals().get('default_lgn_density',24.0),
                nominal_bounds=sheet.BoundingBox(radius=0.5+v1aff_radius),
                output_fn=transferfn.PiecewiseLinear(lower_bound=0.0,upper_bound=1.0),
                measure_maps=False)
        for channel in xrange(2,sf_channels+1):
            topo.sim[e+'LGN'+l+'SF'+str(channel)]=sheet.CFSheet(
                nominal_density=locals().get('default_lgn_density',24.0),
                nominal_bounds=sheet.BoundingBox(radius=0.5+v1aff_radius*sf_spacing**(channel-1)),
                output_fn=transferfn.PiecewiseLinear(lower_bound=0.0,upper_bound=1.0),
                measure_maps=False)
                

topo.sim['V1'] = sheet.lissom.LISSOM(nominal_density=locals().get('default_density',48.0),
                                     tsettle=9,nominal_bounds=sheet.BoundingBox(radius=0.5))

topo.sim['V1'].output_fn.lower_bound=0.076 if dataset in natural_image_sets else 0.083
topo.sim['V1'].output_fn.upper_bound=0.626 if dataset in natural_image_sets else 0.633

# DoG weights for the LGN
centerg   = pattern.Gaussian(size=0.07385,aspect_ratio=1.0,
                             output_fn=transferfn.DivisiveNormalizeL1())
surroundg = pattern.Gaussian(size=0.29540,aspect_ratio=1.0,
                             output_fn=transferfn.DivisiveNormalizeL1())

strength=[2.33, 2.38, 2.53, 2.8] # 2.33 for speed=0, 2.38 for speed=1, 2.53 for speed=2, 2.8 for speed=3 from CMVC
if dataset in natural_image_sets:
    strength=[4.7, 4.8, 5.1, 5.8] 

# Convenience variable; number of afferent connections to V1
num_aff=len(center_polarities)*len(eyes)*len(lags)*len(opponent_types)

for e in eyes:
    for l in center_polarities:
        basic_opponent_types_tmp=list(basic_opponent_types)
        basic_opponent_types_tmp.reverse()
        for (cone,opponentcenter,opponentsurround) in zip(rg_cone_types,basic_opponent_types,basic_opponent_types_tmp):
            topo.sim.connect(
                e+cone+'Retina', e+opponentcenter+'LGN'+l, name='AfferentCenter', 
                connection_type=projection.SharedWeightCFProjection, delay=0.05,
                strength=strength[int(speed)]*(-1)**center_polarities.index(l), 
                nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                weights_generator=centerg)

            topo.sim.connect(
                e+cone+'Retina', e+opponentsurround+'LGN'+l, name='AfferentSurround',
                connection_type=projection.SharedWeightCFProjection, delay=0.05,
                strength=strength[int(speed)]*(-1)**(1+center_polarities.index(l)), 
                nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                weights_generator=surroundg)

            if 'sf' in dims and 'rg' not in dims: 
                for channel in xrange(2,sf_channels+1):
                    topo.sim.connect(
                        e+cone+'Retina', e+opponentcenter+'LGN'+l+'SF'+str(channel), 
                        name='AfferentCenter'+str(channel),
                        delay=0.05,connection_type=projection.SharedWeightCFProjection,
                        strength=strength[int(speed)]*(-1)**center_polarities.index(l), 
                        nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius*sf_spacing**(channel-1)),
                        
                        weights_generator=pattern.Gaussian(size=0.07385*sf_spacing**(channel-1),aspect_ratio=1.0,
                                                           output_fn=transferfn.DivisiveNormalizeL1()))

                    topo.sim.connect(
                        e+cone+'Retina', e+opponentsurround+'LGN'+l+'SF'+str(channel), 
                        name='AfferentSurround'+str(channel),
                        delay=0.05,connection_type=projection.SharedWeightCFProjection,
                        strength=strength[int(speed)]*(-1)**(1+center_polarities.index(l)), 
                        nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius*sf_spacing**(channel-1)),
                            
                        weights_generator=pattern.Gaussian(size=0.29540*sf_spacing**(channel-1),aspect_ratio=1.0,
                                                           output_fn=transferfn.DivisiveNormalizeL1()))

            if 'cr' in dims:
                topo.sim.connect(
                    e+cone+'Retina', e+'Blue-RedGreen'+' LGN'+l, 
                    name='AfferentCenter'+cone,
                    delay=0.05,connection_type=projection.SharedWeightCFProjection,
                    strength=4.7*(-1)**(1+center_polarities.index(l))/2,
                    nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                    weights_generator=centerg)

        if 'cr' in dims:
            topo.sim.connect(
                e+'Blue'+'Retina', e+'Blue-RedGreen'+' LGN'+l, 
                name='AfferentCenter'+'Blue', 
                delay=0.05,connection_type=projection.SharedWeightCFProjection,
                strength=4.7*(-1)**center_polarities.index(l),
                nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                weights_generator=centerg)

        for cone in cone_types:
            if 'Luminosity ' in opponent_types:
                topo.sim.connect(
                    e+cone+'Retina', e+'Luminosity LGN'+l, 
                    name='AfferentCenter'+cone,
                    delay=0.05,connection_type=projection.SharedWeightCFProjection,
                    strength=strength[int(speed)]*(-1)**center_polarities.index(l)/len(cone_types),
                    nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                    weights_generator=centerg)

                topo.sim.connect(
                    e+cone+'Retina', e+'Luminosity LGN'+l, 
                    name='AfferentSurround'+cone, 
                    delay=0.05,connection_type=projection.SharedWeightCFProjection,
                    strength=strength[int(speed)]*(-1)**(1+center_polarities.index(l))/len(cone_types),
                    nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                    weights_generator=surroundg)

                for channel in xrange(2,sf_channels+1):
                    topo.sim.connect(
                        e+cone+'Retina', e+'LGN'+l+'SF'+str(channel), 
                        name='AfferentCenter'+cone+str(channel),
                        delay=0.05,connection_type=projection.SharedWeightCFProjection,
                        strength=strength[int(speed)]*(-1)**center_polarities.index(l)/len(cone_types),
                        nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius*sf_spacing**(channel-1)),
                            
                        weights_generator=pattern.Gaussian(size=0.07385*sf_spacing**(channel-1),aspect_ratio=1.0,
                                                           output_fn=transferfn.DivisiveNormalizeL1()))

                    topo.sim.connect(
                        e+cone+'Retina', e+'LGN'+l+'SF'+str(channel), 
                        name='AfferentSurround'+cone+str(channel),
                        delay=0.05,connection_type=projection.SharedWeightCFProjection,
                        strength=strength[int(speed)]*(-1)**(1+center_polarities.index(l))/len(cone_types),
                        nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius*sf_spacing**(channel-1)),
                            
                        weights_generator=pattern.Gaussian(size=0.29540*sf_spacing**(channel-1),aspect_ratio=1.0,
                                                           output_fn=transferfn.DivisiveNormalizeL1()))

for e in eyes:
    for n in xrange(num_lags):
        for l in center_polarities:
            for opponent in opponent_types:
                topo.sim.connect(
                    e+opponent+'LGN'+l,'V1',delay=0.05+n,
                    dest_port=('Activity','JointNormalize', 'Afferent'),
                    strength=1.0,name=e+opponent+'LGN'+l+'Afferent'+lags[n],
                    connection_type=projection.CFProjection,
                    weights_generator=pattern.random.GaussianCloud(gaussian_size=2*v1aff_radius),
                    nominal_bounds_template=sheet.BoundingBox(radius=v1aff_radius),
                    learning_rate=0.9590/num_aff/ids) 

            for channel in xrange(2,sf_channels+1):
                topo.sim.connect(
                    e+'LGN'+l+'SF'+str(channel),'V1',delay=0.05+n,
                    dest_port=('Activity','JointNormalize', 'Afferent'),
                    strength=1.0,name=e+'LGN'+l+'Afferent'+lags[n]+'SF'+str(channel),
                    connection_type=projection.CFProjection,
                    weights_generator=pattern.random.GaussianCloud(gaussian_size=2*v1aff_radius*sf_spacing**(channel-1)),
                    nominal_bounds_template=sheet.BoundingBox(radius=v1aff_radius*sf_spacing**(channel-1)),
                    learning_rate=0.9590/num_aff/ids) 


topo.sim.connect('V1','V1',delay=0.05,name='LateralExcitatory',
                 connection_type=projection.CFProjection,
                 strength=1.2 if dataset in natural_image_sets else 0.9,
                 weights_generator=pattern.random.GaussianCloud(gaussian_size=2*0.10417),
                 nominal_bounds_template=sheet.BoundingBox(radius=0.10417),
                 learning_rate=2.55528/ids) 
            
topo.sim.connect('V1','V1',delay=0.05,name='LateralInhibitory',
                 connection_type=projection.CFProjection,
                 strength=-1.75 if dataset in natural_image_sets else -0.9, 
                 weights_generator=pattern.random.GaussianCloud(gaussian_size=2*0.22917),
                 nominal_bounds_template=sheet.BoundingBox(radius=0.22917),
                 learning_rate=1.80873/ids/5 if dataset in natural_image_sets else 1.80873/ids)


### Actions scheduled to occur as the simulation proceeds.
st=(1.0/2.0 if dataset in natural_image_sets else 1.0/num_inputs)
sheet.lissom.schedule_events("topo.sim['V1']",st=st,
                             aff_name="Afferent",ids=ids,
                             increase_inhibition=(dataset in natural_image_sets))

# These simulations are slow, so we want more progress reports
topo.sim.schedule_command(25*st,'pass')
topo.sim.schedule_command(50*st,'pass')
topo.sim.schedule_command(100*st,'pass')
topo.sim.schedule_command(150*st,'pass')


### Default locations for model editor
vs=[None]*(num_aff-1) + ['V1'] + [None]*(num_aff)

ls=[]
for e in eyes:
    for l in center_polarities:
        for opponent in opponent_types: 
            ls += [e+opponent+'LGN'+l]+[None]
        for channel in xrange(2,sf_channels+1):
            ls += [e+'LGN'+l+'SF'+str(channel)]+[None]

es=[]
for e in eyes:
    for cone in cone_types:
        es += [None]*(len(center_polarities)/2) + [e+cone+'Retina',None] + \
              [None]*(len(center_polarities)/2)
 
topo.sim.grid_layout([vs,ls,es], xstep=70/len(eyes), ystep=200, item_scale=0.75/len(eyes))


### Set up appropriate defaults for analysis
import topo.command

# Declare which maps to measure
preference_maps=[
('dy',['PhaseDisparity Preference']),
('cr',['Hue Preference']),
('rg',['Hue Preference']),
('dr',['Direction Preference']),
('or',['Orientation Preference']),
('od',['Ocular Preference']),
('sf',['Spatial Frequency Preference']),
]
pgs = [x for y in [m for n,m in preference_maps if n in dims] for x in y] + \
      ['Position Preference','Activity']
topo.command.basic.default_analysis_plotgroups=pgs
    

# By default, measures SF at the sizes of RF used, for speed, but if
# expand_sf_test_range is True, will also test over a larger range,
# including half the size of the smallest and twice the size of the
# largest.
expand_sf_test_range=locals().get('expand_sf_test_range',False)
wide_relative_sizes=[0.5*sf_relative_sizes[0]] + sf_relative_sizes + [2.0*sf_relative_sizes[-1]]
relative_sizes=(wide_relative_sizes if expand_sf_test_range else sf_relative_sizes)


# Set up defaults for measure_sine_pref, which is used for or, od, and sf
from topo.command.analysis import measure_sine_pref
if 'sf' in dims: measure_sine_pref.frequencies = [2.4*s for s in relative_sizes]
if 'od' in dims: measure_sine_pref.num_ocularity=2
# Including the rest in measure_sine_pref is usually not computationally feasible:
#if 'dr' in dims: measure_sine_pref.num_direction=6
#if 'dr' in dims: measure_sine_pref.num_speeds=4
#if 'rg' in dims: measure_sine_pref.num_hue=8
#if 'cr' in dims: measure_sine_pref.num_hue=8
#if 'dy' in dims: measure_sine_pref.num_disparity=6 # 12


# Measure feature maps based on unthresholded initial response for
# speed and reliability
from topo.analysis.featureresponses import MeasureResponseCommand
MeasureResponseCommand.duration=0.175
MeasureResponseCommand.apply_output_fn=False


# CB: I guess we should actually have the specification for these back
# in topo.command.analysis...but not create the objects there. We
# already do that elsewhere with plotgrouptemplates for
# templateplotgroups, right?
from topo.command.pylabplots import overlaid_plots
combined_preference_maps = {
    ('or','od'):dict(
        name='Orientation and Ocular Preference',
        doc='Plot the orientation preference overlaid with ocular dominance boundaries.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference"},{"Strength":"OrientationSelectivity"}],overlay=[("contours","OcularPreference",0.5,"black")])],
        normalize=False),

    ('or','dr'):dict(
        name='Orientation and Direction Preference',
        doc='Plot the orientation preference overlaid with direction preference arrows.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference"}],overlay=[("arrows","DirectionPreference","DirectionSelectivity","white")])],
        normalize=False),

    ('or','dy'):dict(
        name='Orientation and PhaseDisparity Preference',
        doc='Plot the orientation preference overlaid with phase disparity preference boundaries.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference","Confidence":"OrientationSelectivity"},{"Strength":"OrientationSelectivity"}],overlay=[("contours","PhasedisparityPreference",0.83,"magenta"),("contours","PhasedisparityPreference",0.08,"yellow")])],
        normalize=False),

    ('or','cr'):dict(
        name='Orientation and Hue Preference',
        doc='Plot the orientation preference overlaid with hue preference boundaries.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference","Confidence":"OrientationSelectivity"},{"Strength":"OrientationSelectivity"}],overlay=[("contours","HuePreference",0.9,"red"),("contours","HuePreference",0.4,"green")],normalize=True)],
        normalize=True),

    ('or','od','dr'):dict(
        name='Orientation, Ocular and Direction Preference',
        doc='Plot the orientation preference overlaid with ocular dominance boundaries and direction preference arrows.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference"},{"Strength":"OrientationSelectivity"}],overlay=[("contours","OcularPreference",0.5,"black"),("arrows","DirectionPreference","DirectionSelectivity","white")])],
        normalize=False),

    ('od','cr'):dict(
        name='Ocular and Hue Preference',
        doc='Plot the ocular preference overlaid with hue preference boundaries.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OcularPreference","Confidence":"OcularSelectivity"},{"Strength":"OcularSelectivity"}],overlay=[("contours","HuePreference",0.9,"red"),("contours","HuePreference",0.4,"green")],normalize=True)],
        normalize=True)
    }


## Create appropriate combined plots 
from topo.plotting.plotgroup import create_plotgroup
for combined_dimensions,plotgroup_spec in combined_preference_maps.items():
    plotgroup_spec['category']="Combined Preference Maps"
    if set(dims).issuperset(set(combined_dimensions)):
        create_plotgroup(**plotgroup_spec)

# CB: could this be in create_plotgroup?
if hasattr(topo,'guimain'):
    topo.guimain.refresh_plots_menu()

# CJ:to use new direction map measurement (temporary)  
_new_motion_model=True
